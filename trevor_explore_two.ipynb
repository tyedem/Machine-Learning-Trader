{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import finta\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn import\n",
    "\n",
    "\n",
    "bmo = yf.Ticker(\"bmo.to\")\n",
    "#Expected values, stop losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the trained model(s) using testing data. Include any calculations, metrics, or visualizations needed to evaluate the performance.\n",
    "# Show the predictions using a sample of new data. Compare the predictions if more than one model is used.\n",
    "#Use one new machine learning library, machine learning model, or evaluation metric that hasn't been covered in class.\n",
    "\n",
    "#Need a couple of different models, including 1 that hasn't been used.\n",
    "#Need a couple of different predictive tasks - 30 day volume window, 30 day returns etd.\n",
    "#Can vary the TA input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = datetime.date(2012,1,1)\n",
    "# end_date = datetime.date(2022,3,3)\n",
    "# interval = '1d'\n",
    "# period = round((end_date - start_date).days/365,0)\n",
    "# if interval == \"1d\":\n",
    "#     annual_interval = 252\n",
    "#stock_data = yf.download([\"bmo.to\"], start = start_date, end = end_date, interval = interval)\n",
    "loblaw_path = Path(\"./Resources/loblaw.csv\")\n",
    "loblaw_data = pd.read_csv(loblaw_path, parse_dates = True, index_col='Date')\n",
    "shop_path = Path(\"./Resources/shop.csv\")\n",
    "shop_data = pd.read_csv(shop_path, parse_dates = True, index_col='Date')\n",
    "bmo_path = Path(\"./Resources/bmo.csv\")\n",
    "bmo_data = pd.read_csv(shop_path, parse_dates = True, index_col='Date')\n",
    "ticker_list = {\"shopify\":shop_data, \"loblaw\":loblaw_data, \"bmo\":bmo_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>57.057877</td>\n",
       "      <td>57.146301</td>\n",
       "      <td>56.575562</td>\n",
       "      <td>56.905144</td>\n",
       "      <td>52.139797</td>\n",
       "      <td>360760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>56.840836</td>\n",
       "      <td>57.250805</td>\n",
       "      <td>56.696140</td>\n",
       "      <td>57.017685</td>\n",
       "      <td>52.242901</td>\n",
       "      <td>355286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>57.041801</td>\n",
       "      <td>57.258842</td>\n",
       "      <td>56.736336</td>\n",
       "      <td>56.816719</td>\n",
       "      <td>52.058777</td>\n",
       "      <td>458041.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>56.800644</td>\n",
       "      <td>56.800644</td>\n",
       "      <td>56.326366</td>\n",
       "      <td>56.680065</td>\n",
       "      <td>51.933556</td>\n",
       "      <td>324684.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open       High        Low      Close  Adj Close    Volume\n",
       "Date                                                                         \n",
       "<<<<<<< HEAD        NaN        NaN        NaN        NaN        NaN       NaN\n",
       "2017-01-03    57.057877  57.146301  56.575562  56.905144  52.139797  360760.0\n",
       "2017-01-04    56.840836  57.250805  56.696140  57.017685  52.242901  355286.0\n",
       "2017-01-05    57.041801  57.258842  56.736336  56.816719  52.058777  458041.0\n",
       "2017-01-06    56.800644  56.800644  56.326366  56.680065  51.933556  324684.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loblaw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       271\n",
      "         1.0       0.59      1.00      0.74       386\n",
      "\n",
      "    accuracy                           0.59       657\n",
      "   macro avg       0.29      0.50      0.37       657\n",
      "weighted avg       0.35      0.59      0.43       657\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trevo\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\trevo\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\trevo\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15728/199216925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;31m# Print the classification report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_report\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[0maccuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mticker\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"-\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtesting_report\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m     \u001b[0mvoting_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SVM'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msvm_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RFC\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrfc_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lr\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mvoting_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "#Calculate some volume based indicators into the dataframe\n",
    "accuracy = {}\n",
    "for ticker in ticker_list:\n",
    "    stock_data = ticker_list[ticker].copy()\n",
    "    # stock_data['SMA'] = finta.TA.SMA(stock_data)\n",
    "    # stock_data['SMM'] = finta.TA.SMM(stock_data)\n",
    "    # stock_data['SSMA'] = finta.TA.SSMA(stock_data)\n",
    "    # stock_data['EMA'] = finta.TA.EMA(stock_data)\n",
    "    # stock_data['DEMA'] = finta.TA.DEMA(stock_data)\n",
    "    # stock_data['TEMA'] = finta.TA.TEMA(stock_data)\n",
    "    # stock_data['TRIMA'] = finta.TA.TRIMA(stock_data)\n",
    "    # stock_data['TRIX'] = finta.TA.TRIX(stock_data)\n",
    "    # stock_data['VAMA'] = finta.TA.VAMA(stock_data)\n",
    "    # stock_data['ER'] = finta.TA.ER(stock_data)\n",
    "    # stock_data['KAMA'] = finta.TA.KAMA(stock_data)\n",
    "    # stock_data['ZLEMA'] = finta.TA.ZLEMA(stock_data)\n",
    "    # stock_data['WMA'] = finta.TA.WMA(stock_data)\n",
    "    # stock_data['HMA'] = finta.TA.HMA(stock_data)\n",
    "    # stock_data['EVWMA'] = finta.TA.EVWMA(stock_data)\n",
    "    # stock_data['VWAP'] = finta.TA.VWAP(stock_data)\n",
    "    # stock_data['SMMA'] = finta.TA.SMMA(stock_data)\n",
    "    # stock_data['FRAMA'] = finta.TA.FRAMA(stock_data)\n",
    "    # #stock_data['MACD'] = finta.TA.MACD(stock_data)\n",
    "    # #stock_data['PPO'] = finta.TA.PPO(stock_data)\n",
    "    # #stock_data['VW_MACD'] = finta.TA.VW_MACD(stock_data)\n",
    "    # #stock_data['EV_MACD'] = finta.TA.EV_MACD(stock_data)\n",
    "    # stock_data['MOM'] = finta.TA.MOM(stock_data)\n",
    "    # stock_data['ROC'] = finta.TA.ROC(stock_data)\n",
    "    # stock_data['RSI'] = finta.TA.RSI(stock_data)\n",
    "    # stock_data['IFT_RSI'] = finta.TA.IFT_RSI(stock_data)\n",
    "    # stock_data['TR'] = finta.TA.TR(stock_data)\n",
    "    # stock_data['ATR'] = finta.TA.ATR(stock_data)\n",
    "    # stock_data['SAR'] = finta.TA.SAR(stock_data)\n",
    "    # #stock_data['BBANDS'] = finta.TA.BBANDS(stock_data)\n",
    "    # stock_data['BBWIDTH'] = finta.TA.BBWIDTH(stock_data)\n",
    "    # #stock_data['MOBO'] = finta.TA.MOBO(stock_data)\n",
    "    # stock_data['PERCENT_B'] = finta.TA.PERCENT_B(stock_data)\n",
    "    # #stock_data['KC'] = finta.TA.KC(stock_data)\n",
    "    # #stock_data['DO'] = finta.TA.DO(stock_data)\n",
    "    # #stock_data['DMI'] = finta.TA.DMI(stock_data)\n",
    "    # stock_data['ADX'] = finta.TA.ADX(stock_data)\n",
    "    # #stock_data['PIVOT'] = finta.TA.PIVOT(stock_data)\n",
    "    # #stock_data['PIVOT_FIB'] = finta.TA.PIVOT_FIB(stock_data)\n",
    "    # stock_data['STOCH'] = finta.TA.STOCH(stock_data)\n",
    "    # stock_data['STOCHD'] = finta.TA.STOCHD(stock_data)\n",
    "    # stock_data['STOCHRSI'] = finta.TA.STOCHRSI(stock_data)\n",
    "    # stock_data['WILLIAMS'] = finta.TA.WILLIAMS(stock_data)\n",
    "    # stock_data['UO'] = finta.TA.UO(stock_data)\n",
    "    # stock_data['AO'] = finta.TA.AO(stock_data)\n",
    "    # stock_data['MI'] = finta.TA.MI(stock_data)\n",
    "    # #stock_data['VORTEX'] = finta.TA.VORTEX(stock_data)\n",
    "    # #stock_data['KST'] = finta.TA.KST(stock_data)\n",
    "    # #stock_data['TSI'] = finta.TA.TSI(stock_data)\n",
    "    # stock_data['TP'] = finta.TA.TP(stock_data)\n",
    "    # stock_data['ADL'] = finta.TA.ADL(stock_data)\n",
    "    # stock_data['CHAIKIN'] = finta.TA.CHAIKIN(stock_data)\n",
    "    # stock_data['MFI'] = finta.TA.MFI(stock_data)\n",
    "    # stock_data['OBV'] = finta.TA.OBV(stock_data)\n",
    "    # stock_data['WOBV'] = finta.TA.WOBV(stock_data)\n",
    "    # stock_data['VZO'] = finta.TA.VZO(stock_data)\n",
    "    # stock_data['PZO'] = finta.TA.PZO(stock_data)\n",
    "    # stock_data['EFI'] = finta.TA.EFI(stock_data)\n",
    "    # stock_data['CFI'] = finta.TA.CFI(stock_data)\n",
    "    # #stock_data['EBBP'] = finta.TA.EBBP(stock_data)\n",
    "    # stock_data['EMV'] = finta.TA.EMV(stock_data)\n",
    "    # stock_data['CCI'] = finta.TA.CCI(stock_data)\n",
    "    # stock_data['COPP'] = finta.TA.COPP(stock_data)\n",
    "    # #stock_data['BASP'] = finta.TA.BASP(stock_data)\n",
    "    # #stock_data['BASPN'] = finta.TA.BASPN(stock_data)\n",
    "    # stock_data['CMO'] = finta.TA.CMO(stock_data)\n",
    "    # #stock_data['CHANDELIER'] = finta.TA.CHANDELIER(stock_data)\n",
    "    # stock_data['QSTICK'] = finta.TA.QSTICK(stock_data)\n",
    "    # #stock_data['TMF'] = finta.TA.TMF(stock_data)\n",
    "    # #stock_data['WTO'] = finta.TA.WTO(stock_data)\n",
    "    # stock_data['FISH'] = finta.TA.FISH(stock_data)\n",
    "    # #stock_data['ICHIMOKU'] = finta.TA.ICHIMOKU(stock_data)\n",
    "    # #stock_data['APZ'] = finta.TA.APZ(stock_data)\n",
    "    # stock_data['SQZMI'] = finta.TA.SQZMI(stock_data)\n",
    "    # stock_data['VPT'] = finta.TA.VPT(stock_data)\n",
    "    # stock_data['FVE'] = finta.TA.FVE(stock_data)\n",
    "    # stock_data['VFI'] = finta.TA.VFI(stock_data)\n",
    "    # stock_data['MSD'] = finta.TA.MSD(stock_data)\n",
    "    # stock_data['STC'] = finta.TA.STC(stock_data)\n",
    "    #stock_data['WAVEPM'] = finta.TA.WAVEPM(stock_data)\n",
    "\n",
    "    stock_data['mfi'] = finta.TA.MFI(stock_data)\n",
    "    stock_data['mom'] = finta.TA.MOM(stock_data)\n",
    "    stock_data['rsi'] = finta.TA.RSI(stock_data)\n",
    "    stock_data['chaikin'] = finta.TA.CHAIKIN(stock_data)\n",
    "    #https://www.investopedia.com/top-7-technical-analysis-tools-4773275\n",
    "    stock_data['obv'] = finta.TA.OBV(stock_data)\n",
    "    stock_data['adl'] = finta.TA.ADL(stock_data)\n",
    "    stock_data['adx'] = finta.TA.ADX(stock_data)\n",
    "    #stock_data['macd'] = finta.TA.MACD(stock_data)\n",
    "    stock_data['stoch'] = finta.TA.STOCH(stock_data)\n",
    "    #High minus low = new feature (custom loss functions for predictions)\n",
    "    window_size = 15\n",
    "    window_to_adjust = 'Close'\n",
    "    window_name = window_to_adjust + str(window_size) \n",
    "    stock_data[window_name] = stock_data[window_to_adjust].rolling(window=window_size).mean().pct_change().shift(-window_size)\n",
    "    full_df = stock_data.copy()\n",
    "    full_df.to_csv(\"full_df.csv\")\n",
    "    stock_data.dropna(inplace = True)\n",
    "    #stock_data.drop([\"Open\", \"High\",\"Adj Close\",\"Low\",\"Close\",\"Volume\"], axis = 1, inplace = True)\n",
    "    #print(stock_data.head())\n",
    "    #default signal to 0\n",
    "    stock_data['Signal'] = 0.0\n",
    "    # When volume window change is greater than 0, label 1\n",
    "    stock_data.loc[(stock_data[window_name] >= 0), 'Signal'] = 1.0\n",
    "\n",
    "    # When Actual Returns are less than 0, generate signal to sell stock short\n",
    "    stock_data.loc[(stock_data[window_name] < 0), 'Signal'] = 0.0\n",
    "    #Get features and label dataframe\n",
    "    X = stock_data.copy().drop([window_name,'Signal'],axis=1)\n",
    "    y = stock_data['Signal'].copy()\n",
    "    # Select the start of the training period\n",
    "    training_begin = X.index.min()\n",
    "\n",
    "    # Display the training begin date\n",
    "    #print(training_begin)\n",
    "    training_end = training_begin + DateOffset(days=len(y)*.7)\n",
    "\n",
    "    # Display the training end date\n",
    "    #print(training_end)\n",
    "    # Generate the X_train and y_train DataFrames\n",
    "    X_train = X.loc[training_begin:training_end]\n",
    "    y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "    # Review the X_train DataFrame\n",
    "    X_train.tail()\n",
    "    # Generate the X_test and y_test DataFrames\n",
    "    X_test = X.loc[training_end:]\n",
    "    y_test = y.loc[training_end:]\n",
    "    # Scale the features DataFrames\n",
    "\n",
    "    # Create a StandardScaler instance\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Apply the scaler model to fit the X-train data\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    # Transform the X_train and X_test DataFrames using the X_scaler\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    svm_model = svm.SVC()\n",
    "    rfc_model = RandomForestClassifier() \n",
    "    lr_model = LogisticRegression()\n",
    "    # Fit the model to the data using the training data\n",
    "    ml_list = [svm_model, rfc_model, lr_model]\n",
    "    for model in ml_list:\n",
    "        model = model.fit(X_train_scaled, y_train)\n",
    "        # Use the testing data to make the model predictions\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "\n",
    "        # Review the model's predicted values\n",
    "        # Use a classification report to evaluate the model using the predictions and testing data\n",
    "        testing_report = classification_report(\n",
    "            y_test, predictions, output_dict = False)\n",
    "\n",
    "        # Print the classification report\n",
    "        print(testing_report)\n",
    "        accuracy[ticker + \"-\" + model.__class__.__name__] = testing_report['accuracy']\n",
    "    voting_clf = VotingClassifier(estimators = [('SVM',svm_model),(\"RFC\",rfc_model),(\"lr\",lr_model)])\n",
    "    voting_clf.fit(X_train_scaled,y_train)\n",
    "    vote_preds = voting_clf.predict(X_test_scaled)\n",
    "    vote_accuracy = accuracy_score(y_test, vote_preds)\n",
    "    print(ticker + \" \" + str(vote_accuracy))\n",
    "print(accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ticker_list:\n",
    "    print(name)\n",
    "    print(ticker_list[ticker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From instantiate classifier model instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #try GBC\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# gbc_model = GradientBoostingClassifier(\n",
    "#     n_estimators=50,\n",
    "#     learning_rate=.05,\n",
    "#     max_features=3,\n",
    "#     max_depth=2,\n",
    "#     random_state=0)\n",
    "\n",
    "# model.fit(X_train_scaled,y_train.ravel())\n",
    "# predictions = model.predict(X_test_scaled)\n",
    "# print(classification_report(y_test, predictions,output_dict = True)['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0dc138e65a70cb647ce1a270252e71b4bdb55bc5aa19cfa73732b492b7cbef2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
